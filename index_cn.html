<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>邢桢</title>
  
  <meta name="author" content="Zhen Xing">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
	<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>🌐</text></svg>">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <p>[<a href="index.html">English</a>]</p> 

                <name>邢桢</name>
              </p>
              <p>
                  我是一名中国<a href="https://www.fudan.edu.cn/"> 复旦大学</a> <a href="https://cs.fudan.edu.cn/">计算机学院</a>
                  的一年级博士生，我在<a href="http://www.yugangjiang.info/">姜育刚</a>教授和<a href="http://zxwu.azurewebsites.net/"> 吴祖煊</a>研究员的指导下在<a href="https://fvl.fudan.edu.cn/main.htm">视觉与学习实验室 </a>攻读博士学位。
              </p>
              <p>
                  我曾在<a href="http://www.tju.edu.cn/">天津大学 </a>取得了学士学位，同时我在<a href="https://gpantju.github.io/index/">潘刚</a>
                  教授的指导下在计算机视觉实验室研究。          
              </p>
              <p>
                  我硕士就读于复旦大学，在<a href="https://cs.fudan.edu.cn/3f/ab/c25909a278443/page.htm">周向东</a>教授的指导下在大数据实验室研究。
              </p>
              <p>
                  在2022年，我很幸运能在<a href="https://www.microsoft.com/en-us/research/people/qid/">戴琦</a>博士的指导下在微软亚洲研究院<a href="https://www.msra.cn/">(MSRA)</a>作为一名研究型实习生实习。
              </p>
              <p style="text-align:center">
                <a href="mailto:zxing20@fudan.edu.cn">电子邮件</a> &nbsp/&nbsp
                <a href="data/Resume.pdf">个人简历</a> &nbsp/&nbsp
                <!-- <a href="data/JonBarron-bio.txt">Bio</a> &nbsp/&nbsp -->
                <a href="https://scholar.google.com.hk/citations?user=yuiXa5EAAAAJ&hl=zh-CN&oi=ao">谷歌学术</a> &nbsp/&nbsp
                <!-- <a href="https://twitter.com/jon_barron">Twitter</a> &nbsp/&nbsp -->
                <a href="https://github.com/ChenHsing/">Github</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/Zhenxing.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/xz.png" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <heading>研究方向</heading>

          <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <p>
                我的研究兴趣主要是计算机视觉和人工智能。我目前的重点主要是在有限的监督下探索和进行计算机视觉基础研究，
                目标是进行有益于人类的研究和设计产品。我很高兴能成为这个快速发展和迷人领域的一员，我希望能为它的发展做出贡献。
              </p>
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <heading>新闻</heading>
            <ul>
               <li>
                [2022 七月] 三篇论文被计算机视觉顶级会议 <a href="https://eccv2022.ecva.net/">ECCV 2022</a>接收。
              </li>
              <li>
                [2022 六月] 一篇论文被多媒体会议 <a href="https://2022.acmmm.org/">ACM'MM 2022</a>接收。
              </li> 
              <li>
                [2022 五月] 担任 <a href="https://eccv2022.ecva.net/">ECCV 2022</a>审稿人。
              </li>
              <li>
                [2022 五月] 加入 <a href="https://fvl.fudan.edu.cn/main.htm">视觉与学习实验室 </a>, 攻读人工智能方向博士学位。
              </li>
              <li>
                [2022 四月] 一篇论文被 <a href="https://www.icmr2022.org/">ACM ICMR 2022</a>接收。
              </li>
              <li>
                [2022 三月] 开启了我在微软亚洲研究院<a href="https://www.msra.cn/">(MSRA)</a>的研究型实习阶段。
              </li>
              <li>
                [2022 一月] 一篇论文被 <a href="https://www.dasfaa2022.org/">DASFAA 2022</a>接收。
              </li>
              <li>
                [2021 十一月] 被邀请作为 <a href="https://cvpr2022.thecvf.com/">CVPR 2022</a>审稿人。
              </li>
              <li>
                [2021 九月] 一篇论文被 <a href="https://dl.acm.org/journal/tomm">ACM TOMM2021</a>接收。
              </li>
              <li>
                [2020 九月] 加入大数据实验室，开启硕士阶段对计算机视觉方向的研究。
              </li>

            </ul>

        </tbody></table>


        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <heading>发表论文</heading>



          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one" >
                <img src='images/ss3d.png' width="160" mar>
              </div>
 
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
							<!-- <a href="#"> -->
                <papertitle>Semi-supervised Single-view 3D Reconstruction via Prototype Shape Priors</papertitle>
              <!-- </a> -->
              <br>
              <strong>Zhen Xing</strong>,
              Zuxuan Wu*, 
              Hengduo Li, 
              Yu-Gang Jiang
              <br>
              <em>European Conference on Computer Vision(<strong>ECCV</strong>)</em>, 2022  
              <br>
							<!-- <a href="#">[pdf](not aviable)</a> / 
							<a href="#">[code](not aviable)</a>  -->
							<a href="https://arxiv.org/abs/2209.15383">[pdf]</a> / [code]
              <p></p>
              <p>我们首先为有价值的单视图三维重建任务提出了一种半监督的实验设置，为未来的半监督三维重建研究奠定了坚实的基础。
              </p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one" >
                <img src='images/mpcn.jpg' width="160" mar>
              </div>
 
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
							<!-- <a href="#"> -->
                <papertitle>Few-shot Single-view 3D Reconstruction with Memory Prior Contrastive Network</papertitle>
              <!-- </a> -->
              <br>
              <strong>Zhen Xing</strong>,
              Yijiang Chen,
              Zhixin Ling,
              Xiangdong Zhou*, 
              Yu Xiang
              <br>
              <em>European Conference on Computer Vision(<strong>ECCV</strong>)</em>, 2022  
              <br>
							<a href="https://arxiv.org/abs/2208.00183">[pdf]</a> / [code]
              <p></p>
              <p> 针对有监督的三维任务，引入了一种三维感知对比损失。
                  在小样本的实验设置下，我们的方法在ShapeNet和Pascal3D+数据集上全面达到最先进的实验效果。
              </p>
            </td>
          </tr>
				
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one" >
                <img src='images/csr.jpg' width="160" mar>
              </div>
 
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
							<!-- <a href="#"> -->
                <papertitle>Conditional Stroke Recovery for Fine-Grained
                  Sketch-Based Image Retrieval
                  </papertitle>
              <!-- </a> -->
              <br>
              Zhixin Ling, 
              <strong>Zhen Xing</strong>,
              Xiangdong Zhou*
              <br>
              <em>European Conference on Computer Vision(<strong>ECCV</strong>)</em>, 2022  
              <br>
              [pdf] / [code]
              <p></p>
              <p>在四个数据集（即QMUL Shoe、QMUL Chair、QMUL-ShoeV2和Sketchy）上进行了综合实验。依据acc@1指标，
                  我们的方法大大优于以前的工作。
              </p>
            </td>
          </tr>


          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one" >
                <img src='images/mlrm.jpg' width="160" mar>
              </div>
 
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
							<!-- <a href="#"> -->
                <papertitle>Multi-Level Region Matching for Fine-Grained Sketch-Based
                  Image Retrieval
                  </papertitle>
              <!-- </a> -->
              <br>
              Zhixin Ling, 
              <strong>Zhen Xing</strong>, et.al.
              <br>
              <em>ACM International Conference on Multimedia(<strong>MM</strong>)</em>, 2022  
              <br>
              [pdf] / [code]
              <p></p>
              <p>
                我们用多层次多区域匹配来解决细粒度的草图-图像检索问题，针对图片和草图，提出成对区域特征提取方法。
                基于注意力机制，我们提出综合多层多区域特征匹配度的方法。
              </p>
            </td>
          </tr>





          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one" >
                <img src='images/3dpose.png' width="160" mar>
              </div>
 
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
							<!-- <a href="#"> -->
                <papertitle>3D-Augmented Contrastive Knowledge Distillation for 
                  Image-based Object Pose Estimation
                  </papertitle>
              <!-- </a> -->
              <br>
              Zhidan Liu, 
              <strong>Zhen Xing</strong>,
              Xiangdong Zhou*,
              Yijiang Chen
              <br>
              <em>ACM International Conference on Multimedia Retrieval(<strong>ICMR</strong>)</em>, 2022  
              <br>
							<a href="https://arxiv.org/pdf/2206.02531.pdf">[pdf]</a> / [code]
              <p></p>
              <p>
                我们提出了一种新的实验设置，实验性地报告了与现有的基于类别不可知图像的方法相比的最新结果（在ObjectNet3D数据集上提高了5%），证明了我们方法的有效性。
              </p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one" >
                <img src='images/timeseries.jpg' width="160" mar>
              </div>
 
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
							<!-- <a href="#"> -->
                <papertitle>CaSS: A Channel-aware Self-supervised Representation Learning Framework for
                  Multivariate Time Series Classification
                  </papertitle>
              <!-- </a> -->
              <br>
              Yijiang Chen, 
              Xiangdong Zhou,
              <strong>Zhen Xing</strong>,
              Zhidan Liu,
              Minyang Xu

              <br>
              <em>International Conference on Database Systems for Advanced Applications(<strong>DASFFA</strong>)</em>, 2022  
              <br>
							<a href="https://arxiv.org/pdf/2203.04298.pdf">[pdf]</a> / 
							<!-- <a href="#">[code](not aviable)</a>  -->
              [code]
              <p></p>
              <p>
                实验结果表明，与以往的自监督MTS表示学习方法相比，我们的框架实现了新的最先进水平，可以很好地应用于下游多元时间序列分类。
              </p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one" >
                <img src='images/videosumm.jpg' width="160" mar>
              </div>
 
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
							<!-- <a href="#"> -->
                <papertitle>From Coarse to Fine: Hierarchical Structure-aware Video
                  Summarization
                  </papertitle>
              <!-- </a> -->
              <br>
              Wenxu Li, 
              Gang Pan*,
              Chen Wang,
              <strong>Zhen Xing</strong>,
              Zhenjun Han

              <br>
              <em>ACM Transactions on Multimedia Computing, Communications, and Applications(<strong>TOMM</strong>)</em>, 2021 
              <br>
							<a href="https://dl.acm.org/doi/abs/10.1145/3485472">[pdf]</a> / 
							<!-- <a href="#">[code](not aviable)</a>  -->
              [code]
              <p></p>
              <p>我们收集了一个新的数据集，该数据集由具有细粒度动作和重要性注释的结构化游戏视频组成。实验结果证明了我们提出的基于强化学习的
                  方法的有效性。


              </p>
            </td>
          </tr>

        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <heading>荣誉奖项</heading>
            <ul style="list-style-type:none">
              <p style="line-height: 120%; margin-left: 0px; margin-top: 8pt; margin-bottom: 8pt;"> <font face="Arial" size="3">

              <li style="margin-bottom:5px">
                  复旦大学优秀学业奖学金一等奖 <div style="float:right; text-align:right">2022</div>
              </li>
                <li style="margin-bottom:5px">
                  <a href="https://tianchi.aliyun.com/competition/entrance/531904/introduction?spm=5176.12281925.0.0.68067137nX9Tt9">CCKS 2021</a> 国际知识图谱与语义计算大赛 <strong> (排名 6/431)</strong> <div style="float:right; text-align:right">2021</div>
       
              <li style="margin-bottom:5px"><a href="https://challenge.ai.mgtv.com/home">MangoTV</a> 国际音视频算法大赛 <strong> (排名) 6/193)</strong> <div style="float:right; text-align:right">2021</div>
              </li>
                
              <li style="margin-bottom:5px"> 
                天津大学优秀毕业生               <div style="float:right; text-align:right">2020</div>
              </li>
              <li style="margin-bottom:5px">
                 <a href="https://widc.icvrc.cn/">世界智能大会</a>虚拟场景仿真赛二等奖 <div style="float:right; text-align:right">2019</div>
              </li>
           
              <li style="margin-bottom:5px"> 
                天津大学好班长 <div style="float:right; text-align:right">2018</div>
              </li>
         
              <li style="margin-bottom:5px"> 
                天津大学三好学生 <div style="float:right; text-align:right">2017-2020</div>
              </li>
              <br>
              </p>
              </ul>

        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tbody>
          <heading>实习经历</heading>
          <tr>
            <td  style="padding:20px;width:35%;vertical-align:middle">
              <img width="160" src="./images/weiruan.png">
            </td>
            <td style="margin-left:20px;width:65%;vertical-align:middle">
              <div >
                研究型实习生, 微软亚洲研究院, 视觉计算组
              </div>
               2022 三月 - 至今 <br>
               视频动作识别, 时序动作定位，半监督学习
            </td>
          </tr>

          <tr>
            <td  style="padding:20px;width:25%;vertical-align:middle">
              <img width="160" src="./images/zhongqi.png">
            </td>
            <td style="margin-left:20px;width:75%;vertical-align:middle">
              <div >
                算法开发岗, 中国汽车技术研究中心，智能网联平台部
              </div>
               2019 四月 -  2019 七月 <br>
               目标检测, 路径规划算法
            </td>
          </tr>

        </tbody></table>


        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <heading>专业活动</heading>
            <ul style="list-style-type:none">
              <p style="line-height: 120%; margin-left: 0px; margin-top: 8pt; margin-bottom: 8pt;"> <font face="Arial" size="3">
              <li >
                 CVPR, ECCV, MM, CAAI等会议审稿人
              </li>
              <li >
                  复旦大学计算机学院数字图像处理、计算机图像技术课程助教
              </li>
              <br>
              </p>
              </ul>

        </tbody></table>

				
     
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
             
                <p> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;  &copy; 邢桢 | 最后更新时间:  2022 七月。</p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
