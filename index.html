<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Bei Li</title>
  
  <meta name="author" content="Bei Li">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
	<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåê</text></svg>">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <!-- <p>[<a href="index_cn.html">‰∏≠Êñá‰∏ªÈ°µ</a>]</p>  -->
                <name>Bei Li</name>  
                
              </p>
              <p>I am a third year Ph.D student at the Department of <a href="http://www.cse.neu.edu.cn/">Computer Science and Technology</a> at <a href="http://www.neu.edu.cn/"> Northeastern University</a>, China. where I work at <a href="https://www.nlplab.com/">Natural Language Processing Lab </a> under the supervision of Prof. <a href="https://www.nlplab.com/members/xiaotong.html">Tong Xiao</a> and Prof. <a href="https://www.nlplab.com/members/zhujingbo.html"> Jingbo Zhu</a>.
              </p>
              <p>
                At <a href="http://www.tju.edu.cn/">TianJin University </a>, apart from my academics, I work as an undergraduate researcher at the Computer Vision Lab under the supervision of Prof. <a href="https://gpantju.github.io/index/">Gang Pan</a>.              
              </p>
              <p>
                During my master degree at Fudan University, I work at the Big Data and Data Analsis Lab under the supervision of Prof. <a href="https://cs.fudan.edu.cn/3f/ab/c25909a278443/page.htm">Xiangdong Zhou</a>.
              </p>
              <p>
                In the summer of 2022, I am fortunate enough to get an opportunity to work under the guidance of Prof. <a href="https://www.microsoft.com/en-us/research/people/qid/">Qi Dai</a>, as a research intern for the MicroSoft Research Asia<a href="https://www.msra.cn/">(MSRA)</a>.
              </p>
              <p style="text-align:center">
                <a href="mailto:zxing20@fudan.edu.cn">Email</a> &nbsp/&nbsp
                <a href="data/Resume.pdf">Resume</a> &nbsp/&nbsp
                <!-- <a href="data/JonBarron-bio.txt">Bio</a> &nbsp/&nbsp -->
                <a href="https://scholar.google.com.hk/citations?user=yuiXa5EAAAAJ&hl=zh-CN&oi=ao">Google Scholar</a> &nbsp/&nbsp
                <!-- <a href="https://twitter.com/jon_barron">Twitter</a> &nbsp/&nbsp -->
                <a href="https://github.com/ChenHsing/">Github</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/LiBei.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/libei.png" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <heading>Research</heading>

          <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <p>
                I major in natural language processing, especially the sequence generation task, including machine translation, abstractive summarization and etc.
                My current focus majorly is to build parameter-efficient backbone for NLP. 

              </p>
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <heading>News</heading>
            <ul>
              <li>
                [May'2022] Started my internship at MicroSoft Research Asia<a href="https://www.msra.cn/">(MSRA)</a>.
              </li>
               <li>
                [Apr'2022] <strong>One</strong> paper on learning multiscale Transformer models for sequence generation accepted by <a href="https://icml.cc/Conferences/2022">ICML 2022</a>.
              </li>
              <li>
                [Feb'2022] <strong>Two</strong> papers on parameter-efficient backbone and multimodal machine translation accepted by <a href="https://www.2022.aclweb.org/">ACL 2022</a>.
              </li> 
              <li>
                [Apr'2021] <strong>One</strong> paper on knowledge distillation accepted to <a href="https://2021.aclweb.org/">ACL 2021</a>.
              </li>
              <li>
                [Nov'2020] <strong>One</strong> paper on deep Transformer compression accepted to <a href="https://aaai.org/Conferences/AAAI-21/">AAAI 2021</a>.
              </li>
              <li>
                [Sep'2020] <strong>One</strong> paper on shallow-to-deep training for deep Transformer models accepted to <a href="https://2020.emnlp.org/">EMNLP 2020</a>.
              </li>
              <li>
                [Apr'2020] <strong>One</strong> paper on context-aware machine translation accepted to <a href="https://2020.aclweb.org/">ACL 2020</a>.
              </li>
              <li>
                [May'2019] <strong>One</strong> paper on learning deep Transformer models accepted to <a href="https://2019.aclweb.org/">ACL 2019</a>.
              </li>
              

            </ul>

        </tbody></table>


        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <heading>Publications</heading>



          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one" >
                <img src='images/ss3d.png' width="160" mar>
              </div>
 
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
							<!-- <a href="#"> -->
                <papertitle>Learning Multiscale Transformer Models for Sequence Generation</papertitle>
              <!-- </a> -->
              <br>
              <strong>Bei Li</strong>,
              Tong Zheng, Yi Jing, Chengbo Jiao, Tong Xiaoand Jingbo Zhu
              <br>
              <em>International Conference on Machine Learning(<strong>ICML, Spotlight</strong>)</em>, 2022  
              <br>
							<!-- <a href="#">[pdf](not aviable)</a> / 
							<a href="#">[code](not aviable)</a>  -->
							<a href="https://arxiv.org/abs/2209.15383">[pdf]</a> / [code]
              <p></p>
              <p>We re-define the concept of scale for NLP, including scales of sub-word, word and phrase. Our intention is to leverage the word boundaries and phrase-level prior knowledge to compensate for the sub-word features. Then we establish the relationships among different scales, resulting in builting a multiscale Transformer model.
              </p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one" >
                <img src='images/mpcn.jpg' width="160" mar>
              </div>
 
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
							<!-- <a href="#"> -->
                <papertitle>On Vision Features in Multimodal Machine Translation</papertitle>
              <!-- </a> -->
              <br>
              <strong>Bei Li</strong>,
              Chuanhao Lv, Zefan Zhou, Tao Zhou, Tong Xiao, Anxiang Ma and Jingbo Zhu
              <br>
              <em>60th Annual Meeting of the Association for Computational Linguistics(<strong>ACL</strong>)</em>, 2022  
              <br>
							<a href="https://arxiv.org/abs/2208.00183">[pdf]</a> / [code]
							<!-- <a href="#">[code](not aviable)</a>  -->
              <p></p>
              <p> This work investigates the effect of vision features in multimodal machine translation (MMT) scenarios. We proposed three probing tasks to evaluate MMT systems which can help the following researchers. The main contribution is to reveal the importance of strong vision features.</p>
            </td>
          </tr>
				
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one" >
                <img src='images/csr.jpg' width="160" mar>
              </div>
 
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
							<!-- <a href="#"> -->
                <papertitle>ODE Transformer: An Ordinary Differential Equation-Inspired Model for Sequence Generation
                  </papertitle>
              <!-- </a> -->
              <br> 
              <strong>Bei Li</strong>,
              Quan Du, Tao Zhou, Yi Jing, Shuhan Zhou, Xin Zeng, Tong Xiao,and Jingbo Zhu
              <br>
              <em>60th Annual Meeting of the Association for Computational Linguistics(<strong>ECCV</strong>)</em>, 2022  
              <br>
              [pdf] / [code]
              <p></p>
              <p>This work establishes the relationship between ODE and the design of Transformer architecture. We also redesign the Transformer architecture inspired by the lower truncation error achieved by high-order solvers in ODE. ODE Transformer can deliver much better translation performance within the same model capacity. Experimental results on three sequence generation tasks demonstrate the effectiveness.
              </p>
            </td>
          </tr>


          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one" >
                <img src='images/mlrm.jpg' width="160" mar>
              </div>
 
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
							<!-- <a href="#"> -->
                <papertitle>Multi-Level Region Matching for Fine-Grained Sketch-Based
                  Image Retrieval
                  </papertitle>
              <!-- </a> -->
              <br>
              Zhixin Ling, 
              <strong>Zhen Xing</strong>, et.al.
              <br>
              <em>ACM International Conference on Multimedia(<strong>MM</strong>)</em>, 2022  
              <br>
              [pdf] / [code]
              <p></p>
              <p>
                The proposed technique is based on the use of Multi-level region based feature extraction (DRE), 
                obtained using CNN, and a Region Attention Module, which produce Geometry Maps, Positional Embeddings,
                 and weight attention.
              </p>
            </td>
          </tr>





          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one" >
                <img src='images/3dpose.png' width="160" mar>
              </div>
 
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
							<!-- <a href="#"> -->
                <papertitle>3D-Augmented Contrastive Knowledge Distillation for 
                  Image-based Object Pose Estimation
                  </papertitle>
              <!-- </a> -->
              <br>
              Zhidan Liu, 
              <strong>Zhen Xing</strong>,
              Xiangdong Zhou*,
              Yijiang Chen
              <br>
              <em>ACM International Conference on Multimedia Retrieval(<strong>ICMR</strong>)</em>, 2022  
              <br>
							<a href="https://arxiv.org/pdf/2206.02531.pdf">[pdf]</a> / [code]
              <p></p>
              <p>We experimentally report state-of-the-art results
                compared with existing category-agnostic image-based methods by
                a large margin (up to +5% improvement on ObjectNet3D dataset),
                demonstrating the effectiveness of our method.
              </p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one" >
                <img src='images/timeseries.jpg' width="160" mar>
              </div>
 
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
							<!-- <a href="#"> -->
                <papertitle>CaSS: A Channel-aware Self-supervised Representation Learning Framework for
                  Multivariate Time Series Classification
                  </papertitle>
              <!-- </a> -->
              <br>
              Yijiang Chen, 
              Xiangdong Zhou*,
              <strong>Zhen Xing</strong>,
              Zhidan Liu,
              Minyang Xu

              <br>
              <em>International Conference on Database Systems for Advanced Applications(<strong>DASFFA</strong>)</em>, 2022  
              <br>
							<a href="https://arxiv.org/pdf/2203.04298.pdf">[pdf]</a> / 
							<!-- <a href="#">[code](not aviable)</a>  -->
              [code]
              <p></p>
              <p>The experimental results show that our framework achieves new
                state-of-the-art comparing with previous self-supervised MTS representation learning methods
                and can be well applied to the downstream MTS classification.
              </p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one" >
                <img src='images/videosumm.jpg' width="160" mar>
              </div>
 
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
							<!-- <a href="#"> -->
                <papertitle>From Coarse to Fine: Hierarchical Structure-aware Video
                  Summarization
                  </papertitle>
              <!-- </a> -->
              <br>
              Wenxu Li, 
              Gang Pan*,
              Chen Wang,
              <strong>Zhen Xing</strong>,
              Zhenjun Han

              <br>
              <em>ACM Transactions on Multimedia Computing, Communications, and Applications(<strong>TOMM</strong>)</em>, 2021 
              <br>
							<a href="https://dl.acm.org/doi/abs/10.1145/3485472">[pdf]</a> / 
							<!-- <a href="#">[code](not aviable)</a>  -->
              [code]
              <p></p>
              <p>We collect a new dataset that consists of structured game videos with
                fine-grain actions and importance annotations. The experimental results demonstrate the effectiveness of the
                proposed method.
              </p>
            </td>
          </tr>

        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <heading>Honors & Awards</heading>
            <ul style="list-style-type:none">
              <p style="line-height: 120%; margin-left: 0px; margin-top: 8pt; margin-bottom: 8pt;"> <font face="Arial" size="3">

              <li style="margin-bottom:5px">
                  Fudan University excellent academic scholarship. <div style="float:right; text-align:right">2022</div>
              </li>
                <li style="margin-bottom:5px">
                  <a href="https://tianchi.aliyun.com/competition/entrance/531904/introduction?spm=5176.12281925.0.0.68067137nX9Tt9">CCKS 2021</a> National knowledge graph and semantic computing competition <strong> (Rank 6/431)</strong>. <div style="float:right; text-align:right">2021</div>
       
              <li style="margin-bottom:5px"><a href="https://challenge.ai.mgtv.com/home">MangoTV</a> International audio and video algorithm competition <strong> (Rank 6/193)</strong>. <div style="float:right; text-align:right">2021</div>
              </li>
                
              <li style="margin-bottom:5px"> 
                Outstanding graduates of TianJin University.                <div style="float:right; text-align:right">2020</div>
              </li>
              <li style="margin-bottom:5px">
                Second prize of virtual scene group of automatic driving challenge of <a href="https://widc.icvrc.cn/">International Intelligent Conference</a>. <div style="float:right; text-align:right">2019</div>
              </li>
           
              <li style="margin-bottom:5px"> 
                Excellent monitor of Tianjin University. <div style="float:right; text-align:right">2018</div>
              </li>
         
              <li style="margin-bottom:5px"> 
                Academic scholarship of Tianjin University. <div style="float:right; text-align:right">2017-2020</div>
              </li>
              <br>
              </p>
              </ul>

        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tbody>
          <heading>Intern Experiences</heading>
          <tr>
            <td  style="padding:20px;width:35%;vertical-align:middle">
              <img width="160" src="./images/weiruan.png">
            </td>
            <td style="margin-left:20px;width:65%;vertical-align:middle">
              <div >
                Research Intern, MicroSoft Research Asia, Vision Computing
              </div>
              Mar. 2022 - Now <br>
              Video Action Recognition, Temporal Action Detection
            </td>
          </tr>

          <tr>
            <td  style="padding:20px;width:25%;vertical-align:middle">
              <img width="160" src="./images/zhongqi.png">
            </td>
            <td style="margin-left:20px;width:75%;vertical-align:middle">
              <div >
                Intern, China Automotic Technology and Research Center
              </div>
              Apr. 2019 - July. 2019 <br>
              Object Detection, Path Planning.
            </td>
          </tr>

        </tbody></table>


        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <heading>Professional activities</heading>
            <ul style="list-style-type:none">
              <p style="line-height: 120%; margin-left: 0px; margin-top: 8pt; margin-bottom: 8pt;"> <font face="Arial" size="3">
              <li >
                Conference Reviewer for CVPR, ECCV, MM, CAAI
              </li>
              <li >
                Teaching Assistant for Digital Image processing, Computer image technology in Fudan University
              </li>
              <br>
              </p>
              </ul>

        </tbody></table>

				
     
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
             
                <p> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;  &copy; Zhen Xing | Last updated: July. 2022.</p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
