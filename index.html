<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Zhen Xing</title>
  
  <meta name="author" content="Zhen Xing">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
	<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåê</text></svg>">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <p>[<a href="index_cn.html">‰∏≠Êñá‰∏ªÈ°µ</a>]</p> 
                <name>Zhen Xing</name>  

              </p>
              <p>I am a first year Ph.D student at the Department of <a href="https://cs.fudan.edu.cn/">Computer Science</a> at <a href="https://www.fudan.edu.cn/"> Fudan University</a>  , China, where I work at <a href="https://fvl.fudan.edu.cn/main.htm">Vision and Learning Lab </a> under the supervision of Prof. <a href="http://www.yugangjiang.info/">Yu-Gang Jiang</a> and Prof. <a href="http://zxwu.azurewebsites.net/"> Zuxuan Wu</a>.
              </p>
              <p>
                At <a href="http://www.tju.edu.cn/">TianJin University </a>, apart from my academics, I work as an undergraduate researcher at the Computer Vision Lab under the supervision of Prof. <a href="https://gpantju.github.io/index/">Gang Pan</a>.              
              </p>
              <p>
                During my master degree at Fudan University, I work at the Big Data and Data Analsis Lab under the supervision of Prof. <a href="https://cs.fudan.edu.cn/3f/ab/c25909a278443/page.htm">Xiangdong Zhou</a>.
              </p>
              <p>
                In the summer of 2022, I am fortunate enough to get an opportunity to work under the guidance of Prof. <a href="https://www.microsoft.com/en-us/research/people/qid/">Qi Dai</a>, as a research intern for the MicroSoft Research Asia<a href="https://www.msra.cn/">(MSRA)</a>.
              </p>
              <p style="text-align:center">
                <a href="mailto:zxing20@fudan.edu.cn">Email</a> &nbsp/&nbsp
                <a href="data/Resume.pdf">Resume</a> &nbsp/&nbsp
                <!-- <a href="data/JonBarron-bio.txt">Bio</a> &nbsp/&nbsp -->
                <a href="https://scholar.google.com.hk/citations?user=yuiXa5EAAAAJ&hl=zh-CN&oi=ao">Google Scholar</a> &nbsp/&nbsp
                <!-- <a href="https://twitter.com/jon_barron">Twitter</a> &nbsp/&nbsp -->
                <a href="https://github.com/ChenHsing/">Github</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/Zhenxing.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/xz.png" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <heading>Research</heading>

          <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <p>
                My research interests lie broadly in computer vision and artificial intelligence.
                My current focus majorly is to explore and conduct fundamental computer vision 
                research with limited supervision, with a goal to conduct research and design
                products benefiting humanity. I am excited to be part of this fast-evolving and 
                fascinating field, and I hope to contribute to its growth.

              </p>
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <heading>News</heading>
            <ul>
               <li>
                [July'2022] <strong>Three</strong> papers on 3D reconstruction and sketch-based image retrieval accepted by <a href="https://eccv2022.ecva.net/">ECCV 2022</a>.
              </li>
              <li>
                [June'2022] <strong>One</strong> paper on sketch-based image retrieval accepted by <a href="https://2022.acmmm.org/">ACM'MM 2022</a>.
              </li> 
              <li>
                [May'2022] Be acted as a reviewer for <a href="https://eccv2022.ecva.net/">ECCV 2022</a>.
              </li>
              <li>
                [May'2022] Joined <a href="https://fvl.fudan.edu.cn/main.htm">Vision and Learning Lab </a>, as an Ph.D research in Computer Vision.
              </li>
              <li>
                [Apr'2022] <strong>One</strong> paper on 3D pose Estimation accepted to <a href="https://www.icmr2022.org/">ACM ICMR 2022</a>.
              </li>
              <li>
                [Mar'2022] Started my internship at MicroSoft Research Asia<a href="https://www.msra.cn/">(MSRA)</a>.
              </li>
              <li>
                [Jan'2022] <strong>One</strong> paper on Time series self-supervised accepted to <a href="https://www.dasfaa2022.org/">DASFAA 2022</a>.
              </li>
              <li>
                [Nov'2021] Be invited as a reviewer for <a href="https://cvpr2022.thecvf.com/">CVPR 2022</a>.
              </li>
              <li>
                [Sep'2021] One paper on Video Summarization accepted to <a href="https://dl.acm.org/journal/tomm">ACM TOMM2021</a>.
              </li>
              <li>
                [Sep'2020] Joined Big Data Lab, as an master researcher in Computer Vision.
              </li>

            </ul>

        </tbody></table>


        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <heading>Publications</heading>



          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one" >
                <img src='images/ss3d.png' width="160" mar>
              </div>
 
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
							<!-- <a href="#"> -->
                <papertitle>Semi-supervised Single-view 3D Reconstruction via Prototype Shape Priors</papertitle>
              <!-- </a> -->
              <br>
              <strong>Zhen Xing</strong>,
              Hengduo Li, 
              Zuxuan Wu*, 
              Yu-Gang Jiang
              <br>
              <em>European Conference on Computer Vision(<strong>ECCV</strong>)</em>, 2022  
              <br>
							<!-- <a href="#">[pdf](not aviable)</a> / 
							<a href="#">[code](not aviable)</a>  -->
							<a href="https://arxiv.org/abs/2209.15383">[pdf]</a> / [code]
              <p></p>
              <p>We first  propose a semi-supervised settings for valuable single-view 3D reconstruction task, 
                set a strong benchmark and pave the road for future semi-supervised 3D reconstruction research.
              </p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one" >
                <img src='images/mpcn.jpg' width="160" mar>
              </div>
 
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
							<!-- <a href="#"> -->
                <papertitle>Few-shot Single-view 3D Reconstruction with Memory Prior Contrastive Network</papertitle>
              <!-- </a> -->
              <br>
              <strong>Zhen Xing</strong>,
              Yijiang Chen,
              Zhixin Ling,
              Xiangdong Zhou*, 
              Yu Xiang
              <br>
              <em>European Conference on Computer Vision(<strong>ECCV</strong>)</em>, 2022  
              <br>
							<a href="https://arxiv.org/abs/2208.00183">[pdf]</a> / [code]
							<!-- <a href="#">[code](not aviable)</a>  -->
              <p></p>
              <p> A 3D-aware Contrastive Loss is introduced for supervised 3D task. Our method outperform SoTA methods on ShapeNet and Pascal3D+ dataset at the few shot settings.</p>
            </td>
          </tr>
				
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one" >
                <img src='images/csr.jpg' width="160" mar>
              </div>
 
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
							<!-- <a href="#"> -->
                <papertitle>Conditional Stroke Recovery for Fine-Grained
                  Sketch-Based Image Retrieval
                  </papertitle>
              <!-- </a> -->
              <br>
              Zhixin Ling, 
              <strong>Zhen Xing</strong>,
              Xiangdong Zhou*
              <br>
              <em>European Conference on Computer Vision(<strong>ECCV</strong>)</em>, 2022  
              <br>
              [pdf] / [code]
              <p></p>
              <p>Comprehensive experiments are conducted
                on four datasets (i.e., QMUL-Shoe, QMUL-Chair, QMUL-ShoeV2, and
                Sketchy). In terms of acc@1, our method outperforms previous works by
                a great margin.
              </p>
            </td>
          </tr>


          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one" >
                <img src='images/mlrm.jpg' width="160" mar>
              </div>
 
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
							<!-- <a href="#"> -->
                <papertitle>Multi-Level Region Matching for Fine-Grained Sketch-Based
                  Image Retrieval
                  </papertitle>
              <!-- </a> -->
              <br>
              Zhixin Ling, 
              <strong>Zhen Xing</strong>, et.al.
              <br>
              <em>ACM International Conference on Multimedia(<strong>MM</strong>)</em>, 2022  
              <br>
              [pdf] / [code]
              <p></p>
              <p>
                The proposed technique is based on the use of Multi-level region based feature extraction (DRE), 
                obtained using CNN, and a Region Attention Module, which produce Geometry Maps, Positional Embeddings,
                 and weight attention.
              </p>
            </td>
          </tr>





          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one" >
                <img src='images/3dpose.png' width="160" mar>
              </div>
 
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
							<!-- <a href="#"> -->
                <papertitle>3D-Augmented Contrastive Knowledge Distillation for 
                  Image-based Object Pose Estimation
                  </papertitle>
              <!-- </a> -->
              <br>
              Zhidan Liu, 
              <strong>Zhen Xing</strong>,
              Xiangdong Zhou*,
              Yijiang Chen
              <br>
              <em>ACM International Conference on Multimedia Retrieval(<strong>ICMR</strong>)</em>, 2022  
              <br>
							<a href="https://arxiv.org/pdf/2206.02531.pdf">[pdf]</a> / [code]
              <p></p>
              <p>We experimentally report state-of-the-art results
                compared with existing category-agnostic image-based methods by
                a large margin (up to +5% improvement on ObjectNet3D dataset),
                demonstrating the effectiveness of our method.
              </p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one" >
                <img src='images/timeseries.jpg' width="160" mar>
              </div>
 
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
							<!-- <a href="#"> -->
                <papertitle>CaSS: A Channel-aware Self-supervised Representation Learning Framework for
                  Multivariate Time Series Classification
                  </papertitle>
              <!-- </a> -->
              <br>
              Yijiang Chen, 
              Xiangdong Zhou*,
              <strong>Zhen Xing</strong>,
              Zhidan Liu,
              Minyang Xu

              <br>
              <em>International Conference on Database Systems for Advanced Applications(<strong>DASFFA</strong>)</em>, 2022  
              <br>
							<a href="https://arxiv.org/pdf/2203.04298.pdf">[pdf]</a> / 
							<!-- <a href="#">[code](not aviable)</a>  -->
              [code]
              <p></p>
              <p>The experimental results show that our framework achieves new
                state-of-the-art comparing with previous self-supervised MTS representation learning methods
                and can be well applied to the downstream MTS classification.
              </p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one" >
                <img src='images/videosumm.jpg' width="160" mar>
              </div>
 
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
							<!-- <a href="#"> -->
                <papertitle>From Coarse to Fine: Hierarchical Structure-aware Video
                  Summarization
                  </papertitle>
              <!-- </a> -->
              <br>
              Wenxu Li, 
              Gang Pan*,
              Chen Wang,
              <strong>Zhen Xing</strong>,
              Zhenjun Han

              <br>
              <em>ACM Transactions on Multimedia Computing, Communications, and Applications(<strong>TOMM</strong>)</em>, 2021 
              <br>
							<a href="https://dl.acm.org/doi/abs/10.1145/3485472">[pdf]</a> / 
							<!-- <a href="#">[code](not aviable)</a>  -->
              [code]
              <p></p>
              <p>We collect a new dataset that consists of structured game videos with
                fine-grain actions and importance annotations. The experimental results demonstrate the effectiveness of the
                proposed method.
              </p>
            </td>
          </tr>

        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <heading>Honors & Awards</heading>
            <ul style="list-style-type:none">
              <p style="line-height: 120%; margin-left: 0px; margin-top: 8pt; margin-bottom: 8pt;"> <font face="Arial" size="3">

              <li style="margin-bottom:5px">
                  Fudan University excellent academic scholarship. <div style="float:right; text-align:right">2022</div>
              </li>
                <li style="margin-bottom:5px">
                  <a href="https://tianchi.aliyun.com/competition/entrance/531904/introduction?spm=5176.12281925.0.0.68067137nX9Tt9">CCKS 2021</a> National knowledge graph and semantic computing competition <strong> (Rank 6/431)</strong>. <div style="float:right; text-align:right">2021</div>
       
              <li style="margin-bottom:5px"><a href="https://challenge.ai.mgtv.com/home">MangoTV</a> International audio and video algorithm competition <strong> (Rank 6/193)</strong>. <div style="float:right; text-align:right">2021</div>
              </li>
                
              <li style="margin-bottom:5px"> 
                Outstanding graduates of TianJin University.                <div style="float:right; text-align:right">2020</div>
              </li>
              <li style="margin-bottom:5px">
                Second prize of virtual scene group of automatic driving challenge of <a href="https://widc.icvrc.cn/">International Intelligent Conference</a>. <div style="float:right; text-align:right">2019</div>
              </li>
           
              <li style="margin-bottom:5px"> 
                Excellent monitor of Tianjin University. <div style="float:right; text-align:right">2018</div>
              </li>
         
              <li style="margin-bottom:5px"> 
                Academic scholarship of Tianjin University. <div style="float:right; text-align:right">2017-2020</div>
              </li>
              <br>
              </p>
              </ul>

        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tbody>
          <heading>Intern Experiences</heading>
          <tr>
            <td  style="padding:20px;width:35%;vertical-align:middle">
              <img width="160" src="./images/weiruan.png">
            </td>
            <td style="margin-left:20px;width:65%;vertical-align:middle">
              <div >
                Research Intern, MicroSoft Research Asia, Vision Computing
              </div>
              Mar. 2022 - Now <br>
              Video Action Recognition, Temporal Action Detection
            </td>
          </tr>

          <tr>
            <td  style="padding:20px;width:25%;vertical-align:middle">
              <img width="160" src="./images/zhongqi.png">
            </td>
            <td style="margin-left:20px;width:75%;vertical-align:middle">
              <div >
                Intern, China Automotic Technology and Research Center
              </div>
              Apr. 2019 - July. 2019 <br>
              Object Detection, Path Planning.
            </td>
          </tr>

        </tbody></table>


        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <heading>Professional activities</heading>
            <ul style="list-style-type:none">
              <p style="line-height: 120%; margin-left: 0px; margin-top: 8pt; margin-bottom: 8pt;"> <font face="Arial" size="3">
              <li >
                Conference Reviewer for CVPR, ECCV, MM, CAAI
              </li>
              <li >
                Teaching Assistant for Digital Image processing, Computer image technology in Fudan University
              </li>
              <br>
              </p>
              </ul>

        </tbody></table>

				
     
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
             
                <p> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;  &copy; Zhen Xing | Last updated: July. 2022.</p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
